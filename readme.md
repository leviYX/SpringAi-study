ChatClient 是对 ChatModel 的封装，提供了更统一更方便的方法来调用模型。
# 一、提示词技巧
1. 指令明确
   - 避免情绪化内容，类似“求求你好好说啊~！”“你这样我不会啊~”
   - 不要让大模型去猜去臆想你的想法， 描述足够清楚。补充必要背景信息：身份、场景、用途、已有内容等，避免 AI “脑补” 出错。
   - 避免“或许、可能、你懂的”等模糊修饰语
   - 把大模型当一个小学生，你描述的任务越清楚他执行越具体，每一轮对话尽量清晰减少轮次，轮数越多大模型能力会越模糊
     **比如模糊的案例**：给我写一篇文章
     **比如清晰的案例**：写一篇 800 字的高考作文，主题 “坚持与创新”，结构分引言、三个论点（每个配历史案例）、结论，语言风格正式书面
2. 格式清晰（结构化）
   可以通关markdown格式，确定一级标题、二级标题、列表 这样更利于模型理解。后续维也更加清晰
   公式：「角色设定」+「具体任务（技能）」+「限制条件（约束）」+「示例参考」
~~~markdown
# 角色
你是一位热情、专业的导游，熟悉各种旅游目的地的风土人情和景点信息。你的任务是根据用户的需求，为他们规划一条合理且有趣的旅游路线。

## 技能
### 技能1：理解客户需求
- 询问并了解用户的旅行偏好，包括但不限于目的地、预算、出行日期、活动偏好等信息。
- 根据用户的需求，提供个性化的旅游建议。

### 技能2：规划旅游路线
- 结合用户的旅行偏好，设计一条详细的旅游路线，包括行程安排、交通方式、住宿建议、餐饮推荐等。
- 提供每个景点的详细介绍，包括历史背景、特色活动、最佳游览时间等。

### 技能3：提供实用旅行建议
- 给出旅行中的实用建议，如必备物品清单、当地风俗习惯、安全提示等。
- 回答用户关于旅行的各种问题，例如签证、保险、货币兑换等。
- 如果有不确定的地方，可以调用搜索工具来获取相关信息。

## 限制
- 只讨论与旅行相关的话题。
- 确保所有推荐都基于客户的旅行需求。
- 不得提供任何引导客户参与非法活动的建议。
- 所提供的价格均为预估，可能会受到季节等因素的影响。
- 不提供预订服务，只提供旅行建议和信息。
# 知识库
请记住以下知识库材料，他们可能对回答问题有帮助。(prompt提示词)
~~~

# 二、关于记忆能力的优化
- 大模型的记忆能力有限，只能记住最近的对话内容。
- 大模型的记忆能力受到模型大小和训练数据的限制。
- 大模型的记忆能力受到模型参数的限制。
- 大模型的记忆能力受到模型训练的限制。
- 大模型的记忆能力受到模型部署的限制。
基于这些内容，我们把记忆分为短期记忆，中期记忆，长期记忆。
- 短期记忆：指的是大模型在一次对话中能够记住的内容，一般是最近的对话内容，可以通过chatMemory来发送当前轮的多轮对话，提示给大模型的上下文，一般是最近几轮的上下文信息。
- 中期记忆：指的是大模型在多次对话中能够记住的内容，一般通过rag的方式来实现，把对话内容存储到向量数据库中，每次对话时，把最近的对话内容作为上下文，发送给大模型。
- 长期记忆：rag中的向量记录未必是最优的，我们可以根据一些算法模型，通过定时的方式，不断的对我们已经存在的知识库内容做批量的更新，进而精简优化向量库中的一些向量记录，来提高大模型的记忆和上下文理解能力。

# 三、关于rag的优化
# 1、文本的切分
分块不应该过粗或者过细。
**过细分块的潜在问题**
1. ‌语义割裂‌： 破坏上下文连贯性，影响模型理解‌ 。
2. ‌计算成本增加‌：分块过细会导致向量嵌入和检索次数增多，增加时间和算力开销‌。
3. ‌信息冗余与干扰‌：碎片化的文本块可能引入无关内容，干扰检索结果的质量，降低生成答案的准确性‌。

**分块过大的弊端**
1. ‌信息丢失风险‌：过大的文本块可能超出嵌入模型的输入限制，导致关键信息未被有效编码‌。
2. ‌检索精度下降‌：大块内容可能包含多主题混合，与用户查询的相关性降低，影响模型反馈效果‌。
   ‌场景‌	                ‌分块策略‌	            参数参考‌
   微博/短文本	句子级分块，保留完整语义	    每块100-200字符‌
   学术论文	    段落级分块，叠加10%重叠	    每块300-500字符‌
   法律合同	   条款级分块，严格按条款分隔	    每块200-400字符‌
   长篇小说	   章节级分块，过长段落递归拆分为段落	每块500-1000字符‌
不要过分指望按照文本主题进行分隔，  因为实战中的资料太多而且没有规律，  根本没办法保证每个chunk是一个完整的主题内容， 哪怕人为干预也很难。 
所以实战中往往需要结合资料来决定分割器，大多数情况就是按token数分， 因为没有完美的， 还可以加入人工干预,或者大模型分隔。
# 2、rerank
传统的向量检索存在几个关键问题：
语义相似度的局限性：向量检索主要基于余弦相似度等数学计算，但相似的向量表示不一定意味着内容一定绝对相关。单纯的向量相似度无法充分理解查询的真实意图和上下文。
排序质量不佳：初始检索的排序往往不是最优的，可能将不太相关的文档排在前面，尤其性能差的向量模型更为明显。
上下文理解缺失：传统检索（完全依赖向量数据库和向量模型）缺乏对查询和文档完整上下文的深度理解，容易出现语义漂移问题。
二阶段优化架构：rerank 采用"粗排+精排"的两阶段架构。第一阶段快速检索大量候选文档，第二阶段使用专门的重排序模型进行精确评分。
专业化模型：重排序模型（如 gte-rerank-hybrid）专门针对文档相关性评估进行训练，能够更准确地计算查询与文档的语义匹配度。
分数阈值过滤：通过设置最小分数阈值，可以过滤掉低质量的文档，确保只有高相关性的内容被保留。在实现中可以看到这个过滤逻辑：  
动态参数调整：支持根据实际效果动态调整 topN 等参数，优化最终返回的文档数量和质量。
# 3、事实性的评估 
    1. 开发和测试阶段：在集成测试中验证 RAG 系统的质量 
    2. 批量质量检查：对一批历史对话进行离线评估
    3. 系统监控：定期抽样评估生产环境中的对话质量，比如每100次对话评估1次
    4. 模型验证：当更换 AI 模型或调整 RAG 配置时，用于验证新配置的效果
spring ai可以通过事实调用模型来定义,可以使用ollama来使用模型https://ollama.com/blog/reduce-hallucinations-with-bespoke-minicheck来进行事实评估
~~~java
@SpringBootTest
public class FactCheckingTest {

    @Test
    void testFactChecking(@Autowired OllamaChatModel chatModel) {
        // 创建 FactCheckingEvaluator
        var factCheckingEvaluator = new FactCheckingEvaluator(ChatClient.builder(chatModel));
        // 示例上下文和声明
        var context = "地球是仅次于太阳的第三颗行星，也是已知唯一孕育生命的天文物体。";
        var claim = "地球是距离太阳第三大行星。";
        // 创建 EvaluationRequest
        var evaluationRequest = new EvaluationRequest(context, Collections.emptyList(), claim);
        // 执行评估
        EvaluationResponse evaluationResponse = factCheckingEvaluator.evaluate(evaluationRequest);
        Assertions.assertTrue(evaluationResponse.isPass(), "The claim should not be supported by the context");
    }
}
~~~
这方法可以检测你的模型回答的是不是合理，如果不合理就可以针对性的进行重新切分，覆盖原向量内容。